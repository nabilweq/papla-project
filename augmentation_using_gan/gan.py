# -*- coding: utf-8 -*-
"""mll.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lqWbK4ldjEQ61W7q9CAQlspNH1Ym1qps
"""



from google.colab import drive
drive.mount('/content/drive')

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense

!cp -r /content/drive/MyDrive/papladataset /content/dataset

import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
image_size = (224, 224)
batch_size = 32

train_ds = image_dataset_from_directory(
    "/content/dataset/papladataset/train_set",
    labels = "inferred",
    label_mode = 'int',
    validation_split=0.2,
    subset="training",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)

train_ds = image_dataset_from_directory(
    "/content/dataset/papladataset/train_set",
    labels = "inferred",
    label_mode = 'int',
    validation_split=0.2,
    subset="training",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)

test_ds = image_dataset_from_directory(
    "/content/dataset/papladataset/test_set",
    labels = "inferred",
    label_mode = 'int',
    validation_split=0.2,
    subset="training",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)

#visualizing the data
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(int(labels[i]))
        plt.axis("off")



train_ds.class_names

"""***GAN***



"""

from keras.datasets import mnist
from keras.layers import Input, Dense, Reshape, Flatten
from keras.layers import Activation
from keras.layers import LeakyReLU
from keras.models import Sequential, Model
from keras.optimizers import Adam
import tensorflow as tf
import matplotlib.pyplot as plt

import sys

import numpy as np
import cv2
import matplotlib.pyplot as plt
import os

img_rows = 28
img_cols = 28
channels = 1
img_shape = (img_rows, img_cols, channels)

z_dim = 100

"""generator"""

def generator(img_shape, z_dim):
    
    model = Sequential()
    
    # Hidden layer
    model.add(Dense(128, input_dim=z_dim))

    # Leaky ReLU
    model.add(LeakyReLU(alpha=0.01))

    # Output layer with tanh activation
    model.add(Dense(28*28*1, activation='tanh'))
    model.add(Reshape(img_shape))

    z = Input(shape=(z_dim,))
    img = model(z)

    return Model(z, img)

def discriminator(img_shape):
    
    model = Sequential()

    model.add(Flatten(input_shape=img_shape))

    # Hidden layer
    model.add(Dense(128))

    # Leaky ReLU
    model.add(LeakyReLU(alpha=0.01))
    # Output layer with sigmoid activation
    model.add(Dense(1, activation='sigmoid'))

    img = Input(shape=img_shape)
    prediction = model(img)

    return Model(img, prediction)



discriminator = discriminator(img_shape)
discriminator.compile(loss='binary_crossentropy', 
                      optimizer=Adam(), metrics=['accuracy'])

# Build the Generator
generator = generator(img_shape, z_dim)

# Generated image to be used as input
z = Input(shape=(100,))
img = generator(z)

# Keep Discriminator’s parameters constant during Generator training
discriminator.trainable = False

# The Discriminator’s prediction
prediction = discriminator(img)

# Combined GAN model to train the Generator
combined = Model(z, prediction)
combined.compile(loss='binary_crossentropy', optimizer=Adam())

import cv2 as cv
DATASET = '/content/drive/MyDrive/papladataset/Datasets v1/'




IMAGE_HEIGHT = 200
IMAGE_WIDTH = 200


def create_dataset(DATASET_PATH):
    img_data_array = []
    class_name = []
   
    for directory in os.listdir(DATASET_PATH):
        for file in os.listdir(os.path.join(DATASET_PATH, directory)):
            image_path = os.path.join(DATASET_PATH, directory, file)
            image = cv.imread(image_path, cv.COLOR_BGR2RGB)
            image = np.array(image)
            image = image.astype('float32')
            image /= 255 
            img_data_array.append(image)
            class_name.append(directory)

    return img_data_array, class_name


DATA_IMAGES, DATA_LABELS = create_dataset(DATASET)

print(DATA_IMAGES)

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential

import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt



losses = []
accuracies = []

def train(iterations, batch_size, sample_interval):
    
    # Load the dataset
    train_path = "/content/drive/MyDrive/papladataset/Datasets v1"
    X_train = []
   
    for folder in os.listdir(train_path):

    
      sub_path=train_path+"/"+folder

      for img in os.listdir(sub_path):

        split=os.path.splitext(img)
        if(split[1]=='.JPG'):
          

          image_path=sub_path+"/"+img
          

          img_arr=cv2.imread(image_path)

          img_arr=cv2.resize(img_arr,(28,28))

          X_train.append(img_arr)
          
    X_train.shape
    data_slice = 3000
    X_train=np.array(X_train)
    X_train =X_train[:data_slice,:]
    # Rescale -1 to 1
    X_train = X_train / 127.5 - 1.
    X_train = np.expand_dims(X_train, axis=3)

    # Labels for real and fake examples
    real = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))

    for iteration in range(iterations):
        
        # -------------------------
        #  Train the Discriminator
        # -------------------------

        # Select a random batch of real images
        idx = np.random.randint(0, X_train.shape[0], batch_size)
        imgs = X_train[idx]

        # Generate a batch of fake images
        z = np.random.normal(0, 1, (batch_size, 100))
        gen_imgs = generator.predict(z)

        # Discriminator loss
        d_loss_real = discriminator.train_on_batch(imgs, real)
        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
        
        z = np.random.normal(0, 1, (batch_size, 100))
        gen_imgs = generator.predict(z)

        # Generator loss
        g_loss = combined.train_on_batch(z, real)

        if iteration % sample_interval == 0:
            
            # Output training progress
            print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]" % 
                         (iteration, d_loss[0], 100*d_loss[1], g_loss))
            
            # Save losses and accuracies so they can be plotted after training
            losses.append((d_loss[0], g_loss))
            accuracies.append(100*d_loss[1])

            # Output generated image samples 
            sample_images(iteration)

def sample_images(iteration, image_grid_rows=4, image_grid_columns=4):

    # Sample random noise
    z = np.random.normal(0, 1, 
              (image_grid_rows * image_grid_columns, z_dim))

    # Generate images from random noise 
    gen_imgs = generator.predict(z)

    # Rescale images to 0-1
    gen_imgs = 0.5 * gen_imgs + 0.5

    
    # Set image grid
    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, 
                                    figsize=(4,4), sharey=True, sharex=True)
    
    cnt = 0
    for i in range(image_grid_rows):
        for j in range(image_grid_columns):
            # Output image grid
            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')
            axs[i,j].axis('off')
            cnt += 1

import warnings; warnings.simplefilter('ignore')

iterations = 20000
batch_size = 128
sample_interval = 1000



train( 20000,128, 1000)

!nvidia-smi

import shutil
import os
import os
from tqdm.notebook import tqdm
from PIL import Image
from os import listdir
from PIL import Image
import os, sys
import os

try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=True)
    COLAB = True
    print("Note: using Google CoLab")
except:
    print("Note: not using Google CoLab")
    COLAB = False

!mkdir drive/MyDrive/gans_training
!mkdir drive/MyDrive/gans_training/images
!mkdir drive/MyDrive/gans_training/dataset
!mkdir drive/MyDrive/gans_training/experiments

!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html

!cp -r  '/content/drive/MyDrive/papladataset/Datasets v1' '/content/mydata'

cd '/content/drive/MyDrive/papladataset/Datasets v1/first'

!ls -al

import tensorflow as tf
custom_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    directory='/content/drive/MyDrive/papladataset/Datasets v1',
    image_size=(256, 256),
    batch_size=32)

# Define the GAN model
generator = tf.keras.Sequential([
    tf.keras.layers.Dense(7*7*256, input_shape=(100,), use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.LeakyReLU(),
    tf.keras.layers.Reshape((7, 7, 256)),
    tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.LeakyReLU(),
    tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.LeakyReLU(),
    tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')
])

discriminator = tf.keras.Sequential([
    tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[256, 256, 1]),
    tf.keras.layers.LeakyReLU(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),
    tf.keras.layers.LeakyReLU(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1)
])

gan = tf.keras.Sequential([generator, discriminator])
gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))









"""method3
**bold text**
"""

import tensorflow as tf
from tensorflow import  keras
from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU
import numpy as np
import PIL
import os

# Set hyperparameters
batch_size = 32
epochs = 1000
latent_dim = 100
image_size = 64
num_classes = 3

# Define the generator model
def generator_model():
    model = keras.Sequential()
    model.add(Dense(128 * 16 * 16, input_dim=latent_dim))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Reshape((16, 16, 128)))
    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))
    return model

# Define the discriminator model
def discriminator_model():
    model = keras.Sequential()
    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=(image_size, image_size, num_classes)))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    return model

# Define the GAN model that combines the generator and discriminator models
def gan_model(generator, discriminator):
    discriminator.trainable = False
    model = keras.Sequential()
    model.add(generator)
    model.add(discriminator)
    model.compile(loss='binary_crossentropy', optimizer='adam')
    return model

# Load the dataset and normalize the pixel values
def load_dataset():
    
    first_dir = '/content/drive/MyDrive/papladataset/Datasets v1/first'
    second_dir = '/content/drive/MyDrive/papladataset/Datasets v1/second'
    third_dir = '/content/drive/MyDrive/papladataset/Datasets v1/third'
    
    first_images = np.array([np.asarray(PIL.Image.open(first_dir+'/'+fname).resize((image_size,image_size))) for fname in os.listdir(first_dir) if fname.lower().endswith(('.png', '.jpg', '.jpeg'))])
    first_images = (first_images.astype('float32') - 127.5) / 127.5
    second_images = np.array([np.asarray(PIL.Image.open(second_dir+'/'+fname).resize((image_size,image_size))) for fname in os.listdir(second_dir) if fname.lower().endswith(('.png', '.jpg', '.jpeg'))])
    second_images = (second_images.astype('float32') - 127.5) / 127.5
    third_images = np.array([np.asarray(PIL.Image.open(third_dir+'/'+fname).resize((image_size,image_size))) for fname in os.listdir(third_dir) if fname.lower().endswith(('.png', '.jpg', '.jpeg'))])
    third_images = (third_images.astype('float32')- 127.5) / 127.5
    images = np.concatenate((first_images, second_images, third_images))
    np.random.shuffle(images)
    return images



def train_gan(g_model, d_model, gan_model, dataset):
# Generate random noise as input to the generator
  noise = np.random.randn(batch_size, latent_dim)


  for epoch in range(epochs):
      # Select a random batch of images from the dataset
      idx = np.random.randint(0, dataset.shape[0], batch_size)
      real_images = dataset[idx]
      
      # Generate fake images using the generator
      fake_images = g_model.predict(noise)
      
      # Train the discriminator on real and fake images
      d_loss_real = d_model.train_on_batch(real_images, np.ones((batch_size,1)))
      d_loss_fake = d_model.train_on_batch(fake_images, np.zeros((batch_size,1)))
      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
      
      # Train the generator to fool the discriminator
      g_loss = gan_model.train_on_batch(noise, np.ones((batch_size,1)))
      
      # Print the loss for each epoch
      print("Epoch: %d [D loss: %f] [G loss: %f]" % (epoch, d_loss, g_loss))
      
      # Save generated images every 100 epochs
      if epoch % 100 == 0:
          save_images(g_model, epoch)


def save_images(generator, epoch):
# Create a new directory for the generated images
  os.makedirs('generated_images', exist_ok=True)
  noise = np.random.randn(9, latent_dim)
  generated_images = generator.predict(noise)
  generated_images = 0.5 * generated_images + 0.5
  for i in range(9):
      img = PIL.Image.fromarray((generated_images[i] * 255).astype(np.uint8))
      img.save("generated_images/%d_%d.png" % (epoch, i))

dataset = load_dataset()


g_model = generator_model()
d_model = discriminator_model()
gan_model = gan_model(g_model, d_model)